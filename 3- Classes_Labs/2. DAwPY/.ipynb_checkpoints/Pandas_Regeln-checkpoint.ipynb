{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
    "pd.Series([set, list, dict])\n",
    "pd.Series([sum, print, len])[1](\"Oguzhan\")                   # 0 = sum, 1 = print, 2 = len\n",
    "ser.head(3)                                                  # default olarak ilk 5' döner\n",
    "ser.tail(3)                                                  # default olarak son 5'i döner\n",
    "ser.sample(4)                                                # her calistirmada seriden () ici kadar rastgele deger döner\n",
    "ser.sort_index()                                             # default olarak ascending yani artan sirada index döner\n",
    "                                                             # metod old. icin () gerekli\n",
    "                                                             # shift+tab+tab yaptigimda parametre verirse metod oldugunu anlarim\n",
    "ser.sort_index(ascending=False)                              # bu da tersi\n",
    "ser.sort_values()                                            # default olarak ascending yani artan sirada values döner\n",
    "ser.isin([13])                                               # seride 13 var mi? --> isin method, [köseli parantez icinde yazdim]\n",
    "\"terry\" in panser                                            # panser serisinde \"terry\" var mi? --> in condition\n",
    "121 in panser.values                                   # attribut, values() seklinde yani method gibi () ile yazilsa hata verirdi\n",
    "[i for i in \"clarusway\"]                                     # ['c', 'l', 'a', 'r', 'u', 's', 'w', 'a', 'y'] seklinde basti\n",
    "pd.Series([i for i in \"clarusway\"])                          # Series olarak 0 c, 1 l, 2 a ... seklinde altalta basti\n",
    "\n",
    "np.random.seed(seed=1) random degeri her zaman degismesin diye sabitliyorum.\n",
    "ser = pd.Series(np.random.randint(0, 100, 7))\n",
    "\n",
    "# hata verme, ... mesajini ver\n",
    "try:\n",
    "    print(\"The value of the fourth element in the Series:\", ser2[4])\n",
    "except IndexError as error:\n",
    "    print(\"Nope, the index you selected is out of bounds. That's not how you select rows (index) in a Series.\")\n",
    "    \n",
    "panser < 100                                                 # boolen olarak döndü\n",
    "panser[panser < 100]                                         # 100den kücük deger varsa o degeri döner \n",
    "panser[panser < 100] = 999                                   # deger dönmedi 100den kucuk olan index'i kalici olark 999 yapti\n",
    "\n",
    "###                                                     DataFrame                                                            ### \n",
    "pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)\n",
    "data = [1, 2, 3, 4]\n",
    "pd.DataFrame(data)                   # 0,1,2,3 label olarak verdi. column tanimlanmadigi icin \"0\" ismini verdi\n",
    "pd.DataFrame(data, columns=\"column1\" # ',' den sonra ismini yazmadan(column) bir sey girsem 2. sirada index old. icin hata verir.\n",
    "                                     # simdiki hata sebebi column'u bir collection(list,tuple,set) icinde cagirmali\n",
    "pd.DataFrame(data, columns=[\"column1\"])                           # dogru yazim sekli\n",
    "df.rename(columns = {\"new1\": \"a\", \"new2\": \"b\"})                   # kalici degistirmedi\n",
    "                            # kalici degistirmesi icin ya en basta atama yapilmali yada inplace=True(default'u false) yazilmali\n",
    "df.rename(index = {\"a\": 1, \"b\": 2})                               # kalici degistirmedi\n",
    "                            # kalici degistirmesi icin ya en basta atama yapilmali yada inplace=True(default'u false) yazilmali\n",
    "df.shape                                                          # 4*3\n",
    "df.shape[0]                                                       # 4*3 den 4 gelir\n",
    "df.shape[1]                                                       # 4*3 den 3 gelir\n",
    "len(df)                                                           # rows'lar uzunluktur\n",
    "df.ndim                                                           # kac boyutlu\n",
    "df[\"new_column\"] = df[\"X\"] * df[\"Y\"]                              # yeni column olusturdum\n",
    "df.drop(\"new_column\", axis=1)                                     # axis=1 ile ismini verdigim column'u sildi\n",
    "                                            # axis=1 yazmazsam default axis=0. orda da \"new_column\" diye bir sey yok, hata verir \n",
    "df.drop(\"new_column\", axis=1, inplace=True)                       # yeni olusturdugum column'u kalici olarak sildi\n",
    "df.drop(\"C\")                                                      # rows sildim, default axis=0 \n",
    "df.loc[4]                                                         # Series olarak geldi. axis=0 üzerinde calisiyor\n",
    "df.loc[[4]]                                                       # DataFrame olarak geldi\n",
    "df.loc[2:5]                                          # label index üzerinde calisir bu yüzden 2., 3. , 4. ve 5. rowslari getirdi\n",
    "df.iloc[2:5]                                         # numerical index üzerinde calisir, bu yüzden 2., 3., ve 4. rowslari getirdi\n",
    "df.loc['d':'g']['var3']                                           # Series olarak geldi\n",
    "df.loc['d':'g'][['var3']] veya df.loc['d':'g', [\"var3\"]]          # DataFrame olarak geldi\n",
    "df > 10                                                           # boolen olarak döner\n",
    "df[df > 10]                                                       # df'de 10dan büyükler \n",
    "df[df['var1'] > 10]                                               # var1'de 10dan büyükler\n",
    "df[df['var1'] > 10]['var2']                            # var1'de 10dan büyüklerin oldugu satirlar icin var2'deki degerleri getir\n",
    "df[df['var1'] > 10][['var2', \"var3\"]]  # var1'de 10dan büyüklerin oldugu satirlar icin hem var2'deki hem de var3'deki degerleri getir             \n",
    "df[(df['var1'] > 10) & (df['var1'] < 20)]              #  2 veya daha fazla conditions kullanilabilir. | → or, & → and\n",
    "df.reset_index()                                       # reset öncesi olan index'leri de getirdi\n",
    "df.reset_index(drop=True)                              # reset öncesi olan index'leri getirmesin diye drop=True\n",
    "df.reset_index(drop=True, inplace=True)                # kalici degisiklik icin de inplace=True\n",
    "df.index                                         # indexler geldi. birisi M1,M2,M3 olan sütun digeri 1,2,3,1,2,3,5,6,7 olan sütun\n",
    "df.index.names                                         # bu iki sütunun ismi olmadigi icin None olarak geldiler\n",
    "df.index.names = [\"Group\", \"Num\"]                      # index'leri isimlendirdim\n",
    "df.index.levels                                        # unique olarak index isimlerini getirdi\n",
    "df[[\"A\"]]                                              # [] olunca Series olarak, [[]] olunca DataFrame olarak verdi\n",
    "df[[\"A\",\"B\"]]                                          # bir den fazla columns olunca tek [] ile hata verir\n",
    "sns.get_dataset_names()                                # seaborn'da gömülü dataset'ler             \n",
    "df = sns.load_dataset('iris')                          # iris datasetini yükledim\n",
    "df.describe()                                          # describe, numerical column'larin discrete istatistiklerini verir\n",
    "df.describe(include=\"all\")                             # include=\"all\" ekleyince kategorik verileri de tabloya alip özelliklerini verdi\n",
    "df.describe(include=\"object\")                          # include=\"object\" diyerek sadece kategorik verilerin özellikleri gelir\n",
    "df.describe().transpose()                              # veya df.describe().T ile index-column yerleri degisir\n",
    "\n",
    "# Basic Aggregation Methods: count(), mean(), median(), min(), max(), std(), var(), sum(), idxmin(), idxmax(), corr()\n",
    "# Toplu halde islem yaptigimiz metodlara \"AGGREGATION METHODS\" denir.\n",
    "# DateFrame \"input\"um kadar uzunlukta cikti verir. Apply'da gruplama mantigi var\n",
    "# \"transform\" icine fon. alir. Apply'da kullanici tanimli def., lambda vs. koyulamaz.\n",
    "# \"transform\" element-wise(elemean eleman) islem yapar.\n",
    "df.count()                                             # tüm column'lari saydi. count metodu icin axis default 0             \n",
    "df.count(axis=1)                                       # rows'lari saydi            \n",
    "df_nan.count()                                         # count, \"NaN\" degerleri saymaz. boolen degerleri sayar             \n",
    "df.x1.median()                                         # tek column icin median # yada df['x1'].median() seklinde             \n",
    "df.x1.idxmin()                                         # min olan deger kacinci index'de             \n",
    "df.x1.argmin()                                         # Series'e ait bir özellik. DateFrame icin tek bir column'a uygulanabilir            \n",
    "df.std()                                               # standart devision\n",
    "df.sum()                                               # default column boyunca yani axis=0             \n",
    "df.describe()                                          # agg. metodlari toplu halde verdi             \n",
    "np.percentile(df[\"x1\"], 50)                            # percentile 50 = median yani --> np.median(df[\"x1\"]     \n",
    "             \n",
    "#                                               GroupBy\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=NoDefault.no_default,\n",
    "                  observed=False, dropna=True)\n",
    "df1.groupby(\"Company\")                                 # lazy object üretti, aggr. fonk. ile acabilirim             \n",
    "df1.groupby(\"Company\").mean()                          # numeric olan column'lara uyguladi             \n",
    "a = df1.groupby(\"Company\")[\"Sales\"].mean()             # sadece Sales'e uyguladi\n",
    "b = df1.groupby(\"Company\").mean()[\"Sales\"]             # tüm 'df'e yani hem Age hem de Sales'e uyguladi. yukarda sadece 'Sales'e  \n",
    "%timeit a  |  %timeit b                                # yukardakilerin hiz farki             \n",
    "df1.groupby([\"Company\", \"Department\"])                 # lazy object üretti, aggr. fonk. ile acabilirim\n",
    "df1.groupby([\"Company\", \"Department\"]).mean()          # agg. metodu ile actim. multyindex yapti.              \n",
    "df2.agg({\"var1\": [sum], \"var2\": [min]})                # her bir column'a farkli bir agg. uygularken sözlük formati kullanilir \n",
    "                                                       # islemin ciktisini veren kisim [icine] alinarak df haline getirilebilir             \n",
    "df2.agg({\"var1\": [sum, np.mean], \"var2\": [min, max]})  # farkli column'lara farkli uygulama yapilabilir             \n",
    "df2.groupby(\"groups\").agg([min, \"median\", np.max])     # median fonk. degil \"icine yazilmali\" ve strich fonk. olarak cagrilmali             \n",
    "                                                       # np.max NumPy'a ait old. icin sütun ismi \"amax\" olarak geldi\n",
    "df2.groupby(\"groups\").agg({\"var1\": (min, \"max\"), \"var2\": [\"median\", np.mean]})  # dict old. icin value'lar () veya [] kullanilabilir\n",
    "df2.filter([\"var1\"])                            # filter , list-like istedigi icin, liste icine koyunca yani \"[]\" degerleri verdi             \n",
    "df2.filter([\"groups\", \"var1\"])             \n",
    "df2[[\"groups\", \"var1\"]]                                # basic olarak, filter olmaksizin da yapilabilir              \n",
    "df2.filter(regex=\"^va\", axis=1)                        # va ile baslasin. basic olarak yapilamaz, filter gerekli             \n",
    "df2.filter(regex='v..', axis=1)             \n",
    "df2.filter(like=\"var\", axis=1)                         # var gibi yani icinde var olan columnlar\n",
    "df2.filter(like=\"1\", axis=0)                           # label'i 1 gibi olan yani icinde 1 olan rowslar \n",
    "             \n",
    "#                                          .transform()\n",
    "# Apply'in aksine bagimsiz bir DataFrame döndürür. input ne kadarsa o uzunlukta output verir. \n",
    "# Icine fonk. atilmali. Element-wise yani eleman eleman hepsini gezer  \n",
    "# transform, aggregate fonk. uygulanamaz cünkü agg() tek bir output veriyor\n",
    "df_num.transform(lambda x: x + 10)                                          # eleman eleman gezerek 10 ekledi             \n",
    "df_num.transform(lambda x : (x-x.mean()) / x.std())                         # z score formülü  \n",
    "# df_num[[\"var1\"]].transform(np.sum)                                        # sum() aggregate old. icin kullanilamaz\n",
    "                                                                    # transform input kadar cikti verir ama \"sum\" tek bir output!!!\n",
    "             \n",
    "#df_num[[\"var1\"]].transform(np.sqrt) --> basit seylere icin transform kullanmaya gerek yok\n",
    "#np.sqrt(df_num[[\"var1\"]]                # ayni sonuc\n",
    "df_num[\"var1\"].agg(np.sqrt)              # ayni sonuc            \n",
    "               \n",
    "df2.groupby(\"groups\")[\"var1\"].mean()                                              # grupladi ve ayni uzunlukta dönmedi             \n",
    "df2.groupby(\"groups\").transform(\"mean\")                                           # input uzunlugunda geldi             \n",
    "df2[\"var1_mean_transform\"] = df2.groupby(\"groups\")[\"var1\"].transform(\"mean\")      # var1'in mean()'nine göre yeni column ekledi             \n",
    "df2[\"var2_median_transform\"] = df2.groupby(\"groups\")[\"var2\"].transform(\"median\")  # var2'nin \"median\"ina göre de yeni bir column ekledi             \n",
    "\n",
    "#                                          .apply()\n",
    "# apply hem Dataframe hem de Series'e uygulanabilir \n",
    "# groupby ile kullanmak mantikli degil\n",
    "df3.groupby(\"col4\").apply(lambda x: np.mean(df3['col2']))  # col4'e groupby uygulaninca 2 satira düstü\n",
    "df3['col5'] = df3.groupby(\"col4\").apply(lambda x: np.mean(df3['col2']))  # olusan 2 satiri col5 olarak atamak isteyince \n",
    "                                                                         # uzunluklar uyusmadigi icin hepsini \"NaN\" döndü\n",
    "df3['col6'] = df3.groupby(\"col4\")['col2'].transform(np.mean)          # yukarda \"apply\" ile olamayani burda \"transform\" ile yaptim\n",
    "# applymap sadece Dataframe'e uygulanabilir\n",
    "# map eslestirme yapar\n",
    "# map sadece Series'e uygulanabilir\n",
    "df5.apply(lambda x: x[\"B\"] - x[\"A\"], axis=1)  # apply 1'den fazla column'a islem yapabilir             \n",
    "# df5.transform(lambda x: x[\"B\"] - x[\"A\"], axis=1)  # hata verir\n",
    "# transform sadece 1 column'a islem yapabilir yani Series'e yapar ama DataFrame'e yapamaz\n",
    "\n",
    "# Pivot_table, pivotun genellestirilmis halidir. duplicate degerlerle de kullanilabilir \n",
    "# Pivot_table sadece numeric types, pivot ise string types ile de kullanilir\n",
    "# dublicate deger yoksa, orijinal DateFrame'i kullanarak \"shape\" yapmak istiyorsam \"pivot\" kullanmaliyim.\n",
    "# Dataseti manipüle etmek istiyorum(orj. degerin mean, median, sum görmek istiyorum ve bunlarla yeni tablo olusturmak istiyorsam) \n",
    "# dublicate olsun/olmasin pivot_table kullanilmali\n",
    "             \n",
    "# stack() yiginlama yapar. level'larin/ column'larin sayisini arttirir, yani boyut katilmis olur. multyindex arttirilir            \n",
    "# unstack() level'larin/ column'larin sayisini azaltir \n",
    "             \n",
    "#                                               Handling with Missing Values\n",
    "df[\"var1\"].map({\"-\": np.nan})     # map => \"-\" buldu NaN yapti ama digerlerini tanimlamadigim icin bulamadi ve hepsini NaN yapti\n",
    "df[\"var1\"].replace(to_replace = \"-\", value = np.nan)           # replace: bunu, bununla degistir demek. map yerine daha iyi oldu\n",
    "df.gender.map({\"M\": 1, \"F\": 0})  # unique degerleri az olan bir columnda 'map' kullanmak iyi. bu sekilde numerical'e gidebilirim             \n",
    "# dropna sadece missing value degerleri degistirir\n",
    "# drop her seyi düsebilir\n",
    "df.dropna(axis= 0,                         # 'any', axis= 1 ile rows'da herhangi bir tane missing value varsa sütunu yok eder\n",
    "         how = 'any',                      # 'any', axis= 0 ile column'da herhangi bir tane missing value varsa satiri yok eder\n",
    "         thresh= None, \n",
    "         inplace= False)\n",
    "df.dropna(axis= 1,\n",
    "         how = 'all',                      # her satir ve sütunda en az 1 tane NaN olmayan old. icin hic birini yok etmedi\n",
    "         thresh= 9,                        # column'unda 9 tane NaN olmayanlari kurtar\n",
    "         inplace= False)\n",
    "df.drop([1, 3, 5])                                                                  # 1., 3., ve 5.rows'lari sildi\n",
    "df.drop([\"var1\", \"var2\"], axis=1)                                                   # column'dan \"var1\" ve \"var2\" silindi\n",
    "df.drop(index=[1, 3, 5])                                                            # axis kullanmadan index ile drop\n",
    "df.drop(columns=[\"var1\", \"var2\"])                                                   # axis kullanmadan column ile drop\n",
    "df.fillna(0)                                                                        # fillna(0), tün NaN'lari 0 ile dolduruyor\n",
    "df[\"var1\"].fillna(0)                                                                # tek bir column'a fillna\n",
    "df[\"var1\"].fillna(df[\"var1\"].mean())                                                # NaN'lari mean ile doldurdum\n",
    "df.fillna({\"dept\": \"other\", \"var1\": df.var1.mean(), \"var2\": df.var2.median()})      # her column'a ayri atama yaptim\n",
    "df.notna()            # notna ile hangisi MissingValue degildir diye sorulur. True/False dönüyor. False dönenler 'na' degerlerdir\n",
    "df.where(cond=df.notna(), other=df.mean(), axis= 1)# where, False üzerine odaklanir. False olanlari \"other=df.'mean'()\" ile doldur\n",
    "df.interpolate()                 # bos degerleri altindaki ve üstündekinin ortalamasi ile doldurdu. (linspace mantigiyla calisir)\n",
    "df[\"status\"].fillna(method= \"ffill\")                 # pad / ffill kendinden önceki ile doldurur. ilki 'nan' ise dolduramaz\n",
    "df[\"status\"].fillna(method= \"bfill\")                 # backfill / bfill kendinden sonraki ile doldurur. sonun 'nan' ise dolduramaz\n",
    "df[\"status\"].fillna(method= \"bfill\").fillna(method= \"ffill\")  # varsa kendinden sonraki ile yoksa önceki ile doldur. hepsi dolar\n",
    "\n",
    "#                                                 Combining DataFrames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{'current_date': <15}\", current_datetime)  # 15 karaktere sabitledim\n",
    "\n",
    "pwd # nerde calistigimi gösteriyor. pwd calismazsa basina $ isareti\n",
    "#             CSV INPUT\n",
    "pd.read_csv(\"ornekcsv.csv\")  # hangi seperat kullanildigina bakmak lazim\n",
    "pd.read_csv(\"ornekcsv.csv\", sep=\";\", index_col=0)  # index_col=0 yani a sütunu index oldu\n",
    "pd.read_csv(\"ornekcsv.csv\", sep=\";\", usecols=[\"a\", \"c\"])  # usecols calismak istedigim sütunu cagiriyorum\n",
    "pd.read_csv(\"ornekcsv.csv\", sep=\";\", usecols=[\"a\", \"c\"], nrows=5)  # nrows calismak istedigim satir sayisi\n",
    "#             CSV OUTPUT\n",
    "df.to_csv(\"example.csv\")            # ilk basta _csv dosyasini df'e atayarak devam ettim. daha sonra okuturken farkli isim vermek \n",
    "                                    # istersem \"example\" yerine istenilen ad yazilabilir ve öyle kaydolur\n",
    "pd.read_csv(\"example.csv\")                                   # extra index sütununu ekleyerek cikti verdi. önlemek icin 2 yol var\n",
    "pd.read_csv(\"example.csv\", index_co                                               # 1  => index_col=0\n",
    "df.to_csv(\"example.csv\", index=False)                                             # 2  => index=False, bunu en basta yapabilirdim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "             \n",
    "             \n",
    "             \n",
    "\n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
